{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81cbee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84a8964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>See you make your way through the crowd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>And say, \"hello\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Little did I know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>That you were Romeo, you were throwing pebbles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And my daddy said, \"stay away from Juliet\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            lyric\n",
       "0         See you make your way through the crowd\n",
       "1                                And say, \"hello\"\n",
       "2                               Little did I know\n",
       "3  That you were Romeo, you were throwing pebbles\n",
       "4      And my daddy said, \"stay away from Juliet\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('taylor_swift_lyrics1.csv', encoding='latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ed70dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See you make your way through the crowd And say, \"hello\" Little did I know That you were Romeo, you were throwing pebbles And my daddy said, \"stay away from Juliet\" And I was crying on the staircase Begging you, \"please don't go,\" and I said Romeo, take me somewhere we can be alone I'll be waiting, all there's left to do is run You'll be the prince and I'll be the princess It's a love story baby just say \"yes\" So I sneak out to the garden to see you We keep quiet, 'cause we're dead if they knew So close your eyes Escape this town for a little while 'Cause you were Romeo, I was a scarlet letter And my daddy said, \"Stay away from Juliet\" But you were everything to me I was begging you please don't go and I said Romeo, take me somewhere we can be alone I'll be waiting, all there's left to do is run You'll be the prince and I'll be the princess It's a love story baby just say \"yes\" Romeo, save me, they're trying to tell me how to feel This love is difficult, but it's real Don't be afraid, we'll make it out of this mess It's a love story baby just say \"yes\" Oh, oh I got tired of waiting Wondering if you were ever coming around My faith in you was fading When I met you on the outskirts of town, and I said Romeo save me I've been feeling so alone I keep waiting for you but you never come Is this in my head? I don't know what to think He knelt to the ground and pulled out a ring And said: \"Marry me Juliet You'll never have to be alone I love you and that's all I really know I talked to your dad, go pick out a white dress It's a love story baby just say 'yes'\" Oh, oh Oh, oh Because we were both young when I first saw you Hey Stephen, I know looks can be deceiving But I know I saw a light in you And as we walked we were talking I didn't say half the things I wanted to Of all the girls tossing rocks at your window I'll be the one waiting there even when it's cold Hey Stephen, boy, you might have me believing I don't always have to be alone 'Cause I can't help it if you look like an angel Can't help it if I wanna kiss you in the rain so Come feel this magic I've been feeling since I met you Can't help it if there's no one else Mmm, I can't help myself Hey Stephen, I've been holding back this feeling So I got some things to say to you I've seen it all, so I thought But I never seen nobody shine the way you do The way you walk, way you talk, way you say my name It's beautiful, wonderful, don't you ever change Hey Stephen, why are people always leaving? I think you and I should stay the same 'Cause I can't help it if you look like an angel Can't help it if I wanna kiss you in the rain so Come feel this magic I've been feeling since I met you Can't help it if there's no one else Mmm, I can't help myself They're dimming the street lights, you're perfect for me Why aren't you here tonight? I'm waiting alone now, so come on and come out And pull me near and shine, shine, shine Hey Stephen, I could give you fifty reasons Why I should be the one you choose All those other girls, well, they're beautiful But would they write a song for you? 'Cause I can't help it if you look like an angel Can't help it if I wanna kiss you in the rain so Come feel this magic I've been feeling since I met you Can't help it if there's no one else Mmm, I can't help myself 'Cause I can't help it if you look like an angel Can't help it if I wanna kiss you in the rain so Come feel this magic I've been feeling since I met you Can't help it if there's no one else Mmm, I can't help myself Myself Can't help myself I can't help myself Say you're sorry, that face of an angel Comes out just when you need it to As I paced back and forth all this time 'Cause I honestly believed in you Holdin' on, the days drag on Stupid girl, I shoulda known, I shoulda known That I'm not a princess, this ain't a fairytale I'm not the one you'll sweep off her feet, lead her up the stairwell This ain't Hollywood, this is a small town\n"
     ]
    }
   ],
   "source": [
    "column = df['lyric']\n",
    "\n",
    "# Use the join method to concatenate all the values in the column\n",
    "line = ' '.join(column)\n",
    "\n",
    "# Now you can use the line variable as a single string\n",
    "print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bbdf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'you': 2, 'the': 3, 'and': 4, \"can't\": 5, 'help': 6, 'to': 7, 'it': 8, 'be': 9, 'if': 10, 'a': 11, 'this': 12, 'me': 13, 'so': 14, 'say': 15, 'in': 16, 'were': 17, 'all': 18, \"it's\": 19, \"'cause\": 20, \"i've\": 21, 'come': 22, 'one': 23, 'myself': 24, 'romeo': 25, 'said': 26, \"don't\": 27, 'we': 28, 'alone': 29, 'waiting': 30, \"there's\": 31, 'love': 32, 'out': 33, 'but': 34, 'oh': 35, 'been': 36, 'feeling': 37, 'way': 38, 'know': 39, 'my': 40, 'on': 41, \"i'll\": 42, 'is': 43, 'just': 44, 'feel': 45, 'of': 46, 'met': 47, 'hey': 48, 'stephen': 49, 'an': 50, 'angel': 51, 'your': 52, 'was': 53, \"you'll\": 54, 'story': 55, 'baby': 56, 'for': 57, 'when': 58, 'look': 59, 'like': 60, 'wanna': 61, 'kiss': 62, 'rain': 63, 'magic': 64, 'since': 65, 'no': 66, 'else': 67, 'mmm': 68, 'shine': 69, 'that': 70, 'stay': 71, 'juliet': 72, 'go': 73, 'can': 74, 'do': 75, 'princess': 76, 'yes': 77, 'town': 78, \"they're\": 79, 'never': 80, 'have': 81, 'why': 82, \"i'm\": 83, 'see': 84, 'make': 85, 'little': 86, 'daddy': 87, 'away': 88, 'from': 89, 'begging': 90, 'please': 91, 'take': 92, 'somewhere': 93, 'left': 94, 'run': 95, 'prince': 96, 'keep': 97, 'they': 98, 'save': 99, 'got': 100, 'ever': 101, 'think': 102, 'saw': 103, 'as': 104, 'things': 105, 'girls': 106, 'always': 107, 'back': 108, 'seen': 109, 'beautiful': 110, 'should': 111, \"you're\": 112, 'shoulda': 113, 'known': 114, 'not': 115, \"ain't\": 116, 'her': 117, 'through': 118, 'crowd': 119, 'hello': 120, 'did': 121, 'throwing': 122, 'pebbles': 123, 'crying': 124, 'staircase': 125, 'sneak': 126, 'garden': 127, 'quiet': 128, \"we're\": 129, 'dead': 130, 'knew': 131, 'close': 132, 'eyes': 133, 'escape': 134, 'while': 135, 'scarlet': 136, 'letter': 137, 'everything': 138, 'trying': 139, 'tell': 140, 'how': 141, 'difficult': 142, 'real': 143, 'afraid': 144, \"we'll\": 145, 'mess': 146, 'tired': 147, 'wondering': 148, 'coming': 149, 'around': 150, 'faith': 151, 'fading': 152, 'outskirts': 153, 'head': 154, 'what': 155, 'he': 156, 'knelt': 157, 'ground': 158, 'pulled': 159, 'ring': 160, 'marry': 161, \"that's\": 162, 'really': 163, 'talked': 164, 'dad': 165, 'pick': 166, 'white': 167, 'dress': 168, \"'yes'\": 169, 'because': 170, 'both': 171, 'young': 172, 'first': 173, 'looks': 174, 'deceiving': 175, 'light': 176, 'walked': 177, 'talking': 178, \"didn't\": 179, 'half': 180, 'wanted': 181, 'tossing': 182, 'rocks': 183, 'at': 184, 'window': 185, 'there': 186, 'even': 187, 'cold': 188, 'boy': 189, 'might': 190, 'believing': 191, 'holding': 192, 'some': 193, 'thought': 194, 'nobody': 195, 'walk': 196, 'talk': 197, 'name': 198, 'wonderful': 199, 'change': 200, 'are': 201, 'people': 202, 'leaving': 203, 'same': 204, 'dimming': 205, 'street': 206, 'lights': 207, 'perfect': 208, \"aren't\": 209, 'here': 210, 'tonight': 211, 'now': 212, 'pull': 213, 'near': 214, 'could': 215, 'give': 216, 'fifty': 217, 'reasons': 218, 'choose': 219, 'those': 220, 'other': 221, 'well': 222, 'would': 223, 'write': 224, 'song': 225, 'sorry': 226, 'face': 227, 'comes': 228, 'need': 229, 'paced': 230, 'forth': 231, 'time': 232, 'honestly': 233, 'believed': 234, \"holdin'\": 235, 'days': 236, 'drag': 237, 'stupid': 238, 'girl': 239, 'fairytale': 240, 'sweep': 241, 'off': 242, 'feet': 243, 'lead': 244, 'up': 245, 'stairwell': 246, 'hollywood': 247, 'small': 248}\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "#data= 'Star sign, Gemini \\n Brown eyes, fair hair in the light \\n We called time last night \\n And I cant stop thinking about her \\n Her lips upon mine \\n So soft, feelings I dont know the name of \\n Under the clothes we take off \\n Used to be two hearts in love \\n Oh, why, oh why am I alone? \\n Did I, did I do something wrong? \\n Am I the reason, oh, you found someone else? \\n So tell me, girl \\n How can I live without love? \\n How can I be what you want? \\n Cause when the morning comes around \\n Youre still gone and Ill say \\n How can I see through the dark? \\n All I can do is wonder where you are \\n Are you happy in someone elses arms? \\n Well, thats the way to break my heart \\n Thats the way to break my heart \\n Thats the way to break my heart \\n Thats the way to break my heart \\n Thats the way to break my \\n First love never dies \\n Guess Ill see you in another life \\n 12 years down the line \\n Its just one thing, I remember \\n Her lips on mine \\n So soft, feelings I dont know the name of \\n Under the clothes we take off \\n Used to be two hearts in love \\n Oh, why, oh why am I alone? \\n Did I, did I do something wrong? \\n Am I the reason, oh, yeah you found someone else? \\n So tell me, girl \\n How can I live without love? \\n How can I be what you want? \\n Cause when the morning comes around \\n Youre still gone and Ill say \\n How can I see through the dark? \\n All I can do is wonder where you are \\n Are you happy in someone elses arms? \\n Well, thats the way to break my heart \\n Thats the way to break my heart \\n Thats the way to break my heart \\n Thats the way to break my heart \\n Thats the way to break my \\n Thats the \\n Thats the \\n Thats the \\n Did I, did I? \\n Thats the \\n Thats the \\n Thats the way to break my'\n",
    "corpus = line.lower().split('\\n')\n",
    "\n",
    "tokenizer. fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "print(tokenizer.word_index)\n",
    "print(total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b28b53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c63a18a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np. array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7dd030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictors and label\n",
    "xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "\n",
    "ys = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30093d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i': 1, 'you': 2, 'the': 3, 'and': 4, \"can't\": 5, 'help': 6, 'to': 7, 'it': 8, 'be': 9, 'if': 10, 'a': 11, 'this': 12, 'me': 13, 'so': 14, 'say': 15, 'in': 16, 'were': 17, 'all': 18, \"it's\": 19, \"'cause\": 20, \"i've\": 21, 'come': 22, 'one': 23, 'myself': 24, 'romeo': 25, 'said': 26, \"don't\": 27, 'we': 28, 'alone': 29, 'waiting': 30, \"there's\": 31, 'love': 32, 'out': 33, 'but': 34, 'oh': 35, 'been': 36, 'feeling': 37, 'way': 38, 'know': 39, 'my': 40, 'on': 41, \"i'll\": 42, 'is': 43, 'just': 44, 'feel': 45, 'of': 46, 'met': 47, 'hey': 48, 'stephen': 49, 'an': 50, 'angel': 51, 'your': 52, 'was': 53, \"you'll\": 54, 'story': 55, 'baby': 56, 'for': 57, 'when': 58, 'look': 59, 'like': 60, 'wanna': 61, 'kiss': 62, 'rain': 63, 'magic': 64, 'since': 65, 'no': 66, 'else': 67, 'mmm': 68, 'shine': 69, 'that': 70, 'stay': 71, 'juliet': 72, 'go': 73, 'can': 74, 'do': 75, 'princess': 76, 'yes': 77, 'town': 78, \"they're\": 79, 'never': 80, 'have': 81, 'why': 82, \"i'm\": 83, 'see': 84, 'make': 85, 'little': 86, 'daddy': 87, 'away': 88, 'from': 89, 'begging': 90, 'please': 91, 'take': 92, 'somewhere': 93, 'left': 94, 'run': 95, 'prince': 96, 'keep': 97, 'they': 98, 'save': 99, 'got': 100, 'ever': 101, 'think': 102, 'saw': 103, 'as': 104, 'things': 105, 'girls': 106, 'always': 107, 'back': 108, 'seen': 109, 'beautiful': 110, 'should': 111, \"you're\": 112, 'shoulda': 113, 'known': 114, 'not': 115, \"ain't\": 116, 'her': 117, 'through': 118, 'crowd': 119, 'hello': 120, 'did': 121, 'throwing': 122, 'pebbles': 123, 'crying': 124, 'staircase': 125, 'sneak': 126, 'garden': 127, 'quiet': 128, \"we're\": 129, 'dead': 130, 'knew': 131, 'close': 132, 'eyes': 133, 'escape': 134, 'while': 135, 'scarlet': 136, 'letter': 137, 'everything': 138, 'trying': 139, 'tell': 140, 'how': 141, 'difficult': 142, 'real': 143, 'afraid': 144, \"we'll\": 145, 'mess': 146, 'tired': 147, 'wondering': 148, 'coming': 149, 'around': 150, 'faith': 151, 'fading': 152, 'outskirts': 153, 'head': 154, 'what': 155, 'he': 156, 'knelt': 157, 'ground': 158, 'pulled': 159, 'ring': 160, 'marry': 161, \"that's\": 162, 'really': 163, 'talked': 164, 'dad': 165, 'pick': 166, 'white': 167, 'dress': 168, \"'yes'\": 169, 'because': 170, 'both': 171, 'young': 172, 'first': 173, 'looks': 174, 'deceiving': 175, 'light': 176, 'walked': 177, 'talking': 178, \"didn't\": 179, 'half': 180, 'wanted': 181, 'tossing': 182, 'rocks': 183, 'at': 184, 'window': 185, 'there': 186, 'even': 187, 'cold': 188, 'boy': 189, 'might': 190, 'believing': 191, 'holding': 192, 'some': 193, 'thought': 194, 'nobody': 195, 'walk': 196, 'talk': 197, 'name': 198, 'wonderful': 199, 'change': 200, 'are': 201, 'people': 202, 'leaving': 203, 'same': 204, 'dimming': 205, 'street': 206, 'lights': 207, 'perfect': 208, \"aren't\": 209, 'here': 210, 'tonight': 211, 'now': 212, 'pull': 213, 'near': 214, 'could': 215, 'give': 216, 'fifty': 217, 'reasons': 218, 'choose': 219, 'those': 220, 'other': 221, 'well': 222, 'would': 223, 'write': 224, 'song': 225, 'sorry': 226, 'face': 227, 'comes': 228, 'need': 229, 'paced': 230, 'forth': 231, 'time': 232, 'honestly': 233, 'believed': 234, \"holdin'\": 235, 'days': 236, 'drag': 237, 'stupid': 238, 'girl': 239, 'fairytale': 240, 'sweep': 241, 'off': 242, 'feet': 243, 'lead': 244, 'up': 245, 'stairwell': 246, 'hollywood': 247, 'small': 248}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f50d6f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "26/26 [==============================] - 6463s 258s/step - loss: 5.3804 - accuracy: 0.0408\n",
      "Epoch 2/100\n",
      "26/26 [==============================] - 20s 769ms/step - loss: 5.0565 - accuracy: 0.0545\n",
      "Epoch 3/100\n",
      "26/26 [==============================] - 23s 883ms/step - loss: 4.9645 - accuracy: 0.0507\n",
      "Epoch 4/100\n",
      "26/26 [==============================] - 26s 1s/step - loss: 4.8896 - accuracy: 0.0545\n",
      "Epoch 5/100\n",
      "26/26 [==============================] - 28s 1s/step - loss: 4.7696 - accuracy: 0.0507\n",
      "Epoch 6/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 4.6656 - accuracy: 0.0644\n",
      "Epoch 7/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 4.5733 - accuracy: 0.0656\n",
      "Epoch 8/100\n",
      "26/26 [==============================] - 25s 959ms/step - loss: 4.4852 - accuracy: 0.0569\n",
      "Epoch 9/100\n",
      "26/26 [==============================] - 24s 934ms/step - loss: 4.3829 - accuracy: 0.0804\n",
      "Epoch 10/100\n",
      "26/26 [==============================] - 24s 927ms/step - loss: 4.3253 - accuracy: 0.0792\n",
      "Epoch 11/100\n",
      "26/26 [==============================] - 24s 922ms/step - loss: 4.2020 - accuracy: 0.0854\n",
      "Epoch 12/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 4.1125 - accuracy: 0.0965\n",
      "Epoch 13/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 3.9991 - accuracy: 0.1176\n",
      "Epoch 14/100\n",
      "26/26 [==============================] - 29s 1s/step - loss: 3.8933 - accuracy: 0.1151\n",
      "Epoch 15/100\n",
      "26/26 [==============================] - 28s 1s/step - loss: 3.7739 - accuracy: 0.1238\n",
      "Epoch 16/100\n",
      "26/26 [==============================] - 26s 992ms/step - loss: 3.6720 - accuracy: 0.1485\n",
      "Epoch 17/100\n",
      "26/26 [==============================] - 28s 1s/step - loss: 3.5629 - accuracy: 0.1535\n",
      "Epoch 18/100\n",
      "26/26 [==============================] - 25s 969ms/step - loss: 3.4267 - accuracy: 0.1572\n",
      "Epoch 19/100\n",
      "26/26 [==============================] - 24s 929ms/step - loss: 3.3306 - accuracy: 0.1894\n",
      "Epoch 20/100\n",
      "26/26 [==============================] - 25s 948ms/step - loss: 3.2463 - accuracy: 0.1906\n",
      "Epoch 21/100\n",
      "26/26 [==============================] - 25s 943ms/step - loss: 3.1187 - accuracy: 0.2079\n",
      "Epoch 22/100\n",
      "26/26 [==============================] - 24s 932ms/step - loss: 3.0079 - accuracy: 0.2376\n",
      "Epoch 23/100\n",
      "26/26 [==============================] - 25s 960ms/step - loss: 2.9050 - accuracy: 0.2364\n",
      "Epoch 24/100\n",
      "26/26 [==============================] - 25s 960ms/step - loss: 2.8152 - accuracy: 0.2723\n",
      "Epoch 25/100\n",
      "26/26 [==============================] - 25s 951ms/step - loss: 2.7527 - accuracy: 0.2772\n",
      "Epoch 26/100\n",
      "26/26 [==============================] - 26s 981ms/step - loss: 2.6725 - accuracy: 0.3057\n",
      "Epoch 27/100\n",
      "26/26 [==============================] - 25s 947ms/step - loss: 2.5854 - accuracy: 0.3478\n",
      "Epoch 28/100\n",
      "26/26 [==============================] - 24s 923ms/step - loss: 2.5090 - accuracy: 0.3465\n",
      "Epoch 29/100\n",
      "26/26 [==============================] - 25s 954ms/step - loss: 2.4234 - accuracy: 0.3614\n",
      "Epoch 30/100\n",
      "26/26 [==============================] - 25s 948ms/step - loss: 2.3450 - accuracy: 0.3960\n",
      "Epoch 31/100\n",
      "26/26 [==============================] - 25s 949ms/step - loss: 2.2583 - accuracy: 0.4257\n",
      "Epoch 32/100\n",
      "26/26 [==============================] - 25s 959ms/step - loss: 2.2053 - accuracy: 0.4332\n",
      "Epoch 33/100\n",
      "26/26 [==============================] - 25s 971ms/step - loss: 2.1396 - accuracy: 0.4505\n",
      "Epoch 34/100\n",
      "26/26 [==============================] - 25s 966ms/step - loss: 2.0493 - accuracy: 0.4839\n",
      "Epoch 35/100\n",
      "26/26 [==============================] - 25s 972ms/step - loss: 2.0067 - accuracy: 0.4876\n",
      "Epoch 36/100\n",
      "26/26 [==============================] - 25s 972ms/step - loss: 1.9985 - accuracy: 0.4926\n",
      "Epoch 37/100\n",
      "26/26 [==============================] - 25s 959ms/step - loss: 1.9440 - accuracy: 0.4938\n",
      "Epoch 38/100\n",
      "26/26 [==============================] - 25s 967ms/step - loss: 1.8964 - accuracy: 0.5186\n",
      "Epoch 39/100\n",
      "26/26 [==============================] - 26s 996ms/step - loss: 1.8703 - accuracy: 0.5062\n",
      "Epoch 40/100\n",
      "26/26 [==============================] - 26s 982ms/step - loss: 1.7982 - accuracy: 0.5309\n",
      "Epoch 41/100\n",
      "26/26 [==============================] - 25s 960ms/step - loss: 1.7623 - accuracy: 0.5693\n",
      "Epoch 42/100\n",
      "26/26 [==============================] - 25s 963ms/step - loss: 1.6962 - accuracy: 0.5644\n",
      "Epoch 43/100\n",
      "26/26 [==============================] - 25s 969ms/step - loss: 1.6274 - accuracy: 0.6101\n",
      "Epoch 44/100\n",
      "26/26 [==============================] - 25s 979ms/step - loss: 1.5838 - accuracy: 0.6287\n",
      "Epoch 45/100\n",
      "26/26 [==============================] - 25s 974ms/step - loss: 1.5544 - accuracy: 0.6200\n",
      "Epoch 46/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 1.5555 - accuracy: 0.6126\n",
      "Epoch 47/100\n",
      "26/26 [==============================] - 26s 987ms/step - loss: 1.4877 - accuracy: 0.6423\n",
      "Epoch 48/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 1.4244 - accuracy: 0.6423\n",
      "Epoch 49/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 1.3754 - accuracy: 0.6708\n",
      "Epoch 50/100\n",
      "26/26 [==============================] - 25s 966ms/step - loss: 1.3732 - accuracy: 0.6795\n",
      "Epoch 51/100\n",
      "26/26 [==============================] - 26s 1s/step - loss: 1.4021 - accuracy: 0.6597\n",
      "Epoch 52/100\n",
      "26/26 [==============================] - 26s 984ms/step - loss: 1.4457 - accuracy: 0.6337\n",
      "Epoch 53/100\n",
      "26/26 [==============================] - 25s 957ms/step - loss: 1.3720 - accuracy: 0.6535\n",
      "Epoch 54/100\n",
      "26/26 [==============================] - 25s 944ms/step - loss: 1.2704 - accuracy: 0.7104\n",
      "Epoch 55/100\n",
      "26/26 [==============================] - 25s 967ms/step - loss: 1.2193 - accuracy: 0.7030\n",
      "Epoch 56/100\n",
      "26/26 [==============================] - 25s 966ms/step - loss: 1.1728 - accuracy: 0.7240\n",
      "Epoch 57/100\n",
      "26/26 [==============================] - 25s 973ms/step - loss: 1.1407 - accuracy: 0.7649\n",
      "Epoch 58/100\n",
      "26/26 [==============================] - 26s 990ms/step - loss: 1.1024 - accuracy: 0.7587\n",
      "Epoch 59/100\n",
      "26/26 [==============================] - 26s 1s/step - loss: 1.0685 - accuracy: 0.7797\n",
      "Epoch 60/100\n",
      "26/26 [==============================] - 25s 977ms/step - loss: 1.0499 - accuracy: 0.7611\n",
      "Epoch 61/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 1.0180 - accuracy: 0.7983\n",
      "Epoch 62/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.9992 - accuracy: 0.8020\n",
      "Epoch 63/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.9941 - accuracy: 0.7822\n",
      "Epoch 64/100\n",
      "26/26 [==============================] - 26s 994ms/step - loss: 0.9878 - accuracy: 0.7970\n",
      "Epoch 65/100\n",
      "26/26 [==============================] - 26s 1s/step - loss: 0.9456 - accuracy: 0.8020\n",
      "Epoch 66/100\n",
      "26/26 [==============================] - 26s 997ms/step - loss: 0.9352 - accuracy: 0.8255\n",
      "Epoch 67/100\n",
      "26/26 [==============================] - 26s 997ms/step - loss: 0.8992 - accuracy: 0.8144\n",
      "Epoch 68/100\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.8818 - accuracy: 0.8181\n",
      "Epoch 69/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.8508 - accuracy: 0.8416\n",
      "Epoch 70/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.8109 - accuracy: 0.8614\n",
      "Epoch 71/100\n",
      "26/26 [==============================] - 25s 974ms/step - loss: 0.8535 - accuracy: 0.8304\n",
      "Epoch 72/100\n",
      "26/26 [==============================] - 25s 980ms/step - loss: 0.8927 - accuracy: 0.8119\n",
      "Epoch 73/100\n",
      "26/26 [==============================] - 27s 1s/step - loss: 0.8508 - accuracy: 0.8354\n",
      "Epoch 74/100\n",
      "26/26 [==============================] - 28s 1s/step - loss: 0.7900 - accuracy: 0.8478\n",
      "Epoch 75/100\n",
      "26/26 [==============================] - 24s 937ms/step - loss: 0.7773 - accuracy: 0.8540\n",
      "Epoch 76/100\n",
      "26/26 [==============================] - 25s 965ms/step - loss: 0.7977 - accuracy: 0.8441\n",
      "Epoch 77/100\n",
      "26/26 [==============================] - 23s 902ms/step - loss: 0.7639 - accuracy: 0.8589\n",
      "Epoch 78/100\n",
      "26/26 [==============================] - 24s 911ms/step - loss: 0.7060 - accuracy: 0.8762\n",
      "Epoch 79/100\n",
      "26/26 [==============================] - 23s 877ms/step - loss: 0.6668 - accuracy: 0.8849\n",
      "Epoch 80/100\n",
      "26/26 [==============================] - 24s 912ms/step - loss: 0.6317 - accuracy: 0.9072\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 23s 883ms/step - loss: 0.6069 - accuracy: 0.9134\n",
      "Epoch 82/100\n",
      "26/26 [==============================] - 23s 876ms/step - loss: 0.5938 - accuracy: 0.9245\n",
      "Epoch 83/100\n",
      "26/26 [==============================] - 23s 890ms/step - loss: 0.6079 - accuracy: 0.8960\n",
      "Epoch 84/100\n",
      "26/26 [==============================] - 23s 885ms/step - loss: 0.5890 - accuracy: 0.9134\n",
      "Epoch 85/100\n",
      "26/26 [==============================] - 23s 902ms/step - loss: 0.5646 - accuracy: 0.9171\n",
      "Epoch 86/100\n",
      "26/26 [==============================] - 23s 894ms/step - loss: 0.5491 - accuracy: 0.9332\n",
      "Epoch 87/100\n",
      "26/26 [==============================] - 24s 915ms/step - loss: 0.5487 - accuracy: 0.9220\n",
      "Epoch 88/100\n",
      "26/26 [==============================] - 24s 903ms/step - loss: 0.6186 - accuracy: 0.8948\n",
      "Epoch 89/100\n",
      "26/26 [==============================] - 23s 901ms/step - loss: 0.5724 - accuracy: 0.9158\n",
      "Epoch 90/100\n",
      "26/26 [==============================] - 23s 893ms/step - loss: 0.5639 - accuracy: 0.9282\n",
      "Epoch 91/100\n",
      "26/26 [==============================] - 23s 873ms/step - loss: 0.5195 - accuracy: 0.9282\n",
      "Epoch 92/100\n",
      "26/26 [==============================] - 24s 916ms/step - loss: 0.5118 - accuracy: 0.9295\n",
      "Epoch 93/100\n",
      "26/26 [==============================] - 24s 910ms/step - loss: 0.4888 - accuracy: 0.9344\n",
      "Epoch 94/100\n",
      "26/26 [==============================] - 24s 905ms/step - loss: 0.4863 - accuracy: 0.9282\n",
      "Epoch 95/100\n",
      "26/26 [==============================] - 23s 902ms/step - loss: 0.4746 - accuracy: 0.9394\n",
      "Epoch 96/100\n",
      "26/26 [==============================] - 24s 910ms/step - loss: 0.4548 - accuracy: 0.9455\n",
      "Epoch 97/100\n",
      "26/26 [==============================] - 24s 920ms/step - loss: 0.4375 - accuracy: 0.9554\n",
      "Epoch 98/100\n",
      "26/26 [==============================] - 24s 920ms/step - loss: 0.4122 - accuracy: 0.9616\n",
      "Epoch 99/100\n",
      "26/26 [==============================] - 24s 931ms/step - loss: 0.4206 - accuracy: 0.9542\n",
      "Epoch 100/100\n",
      "26/26 [==============================] - 24s 943ms/step - loss: 0.4082 - accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(40, return_sequences=True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Bidirectional(LSTM(80)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(xs, ys, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22e376a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i keep waiting for you but you never come the way my the way you crowd and hello little did i know that you were romeo you were throwing pebbles and my daddy said stay away from juliet and i was crying on the staircase begging you please don't go and i said romeo take me somewhere we can be alone i'll be waiting all there's left to do is run you'll be the prince and i'll be the princess it's a love story baby just say yes romeo save me they're trying to tell to feel this love is difficult difficult but it's but it's real but it's\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"i keep waiting for you but you never come\"\n",
    "next_words = 100\n",
    "\n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = np.argmax(model.predict(token_list, verbose=0),axis=1)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89f1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c84ed8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
